{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install farm-haystack[elasticsearch] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset subjqa (C:/Users/nikit/.cache/huggingface/datasets/subjqa/electronics/1.1.0/2c12e496c4c675ab4a57ffb5d3f538f2e7b89793956e50da37126393ce23b6c6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c478fcaed55740829a9a36a412098e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "subjqa = load_dataset('subjqa', name='electronics')\n",
    "\n",
    "MINI_CKPT = 'deepset/minilm-uncased-squad2'  # 0.1 GB\n",
    "ROBERTA_CKPT = 'deepset/roberta-base-squad2' # 0.5 GB\n",
    "\n",
    "model_ckpt = MINI_CKPT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids : tensor([[  101,  2054,  7337,  2106,  1996,  1059,  1011, 23821,  2224,  2005,\n",
      "          2491,  1029,   102,  1996,  6119,  3428,  5520,  1996,  5013,  1011,\n",
      "          3498, 13297,  2006,  2285,  2459,  1010,  5778,  1012,  2037,  2948,\n",
      "          1010,  1996,  1059,  1011, 23821,  1010,  2109,  9932,  3917,  5644,\n",
      "          2005,  2491,  1998,  2018,  1037,  2260,  1011, 15149,  3194,  1012,\n",
      "           102]])\n",
      "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])\n",
      "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])\n",
      "[CLS] what mechanism did the w - flyer use for control? [SEP] the wright brothers flew the motor - operated airplane on december 17, 1903. their aircraft, the w - flyer, used ailerons for control and had a 12 - horsepower engine. [SEP]\n"
     ]
    }
   ],
   "source": [
    "question1 = \"What mechanism did the W-Flyer use for control?\" # ailerons\n",
    "question2 = \"What Wright brothers used to fly?\" # the W-Flyer\n",
    "question3 = \"When Wright brothers flew?\" # december 17, 1903\n",
    "question4 = \"How many horsepower had W-Flyer?\" # 12\n",
    "\n",
    "\n",
    "context = \"The Wright brothers flew the motor-operated airplane on December 17, 1903. Their aircraft, the W-Flyer, used ailerons for control and had a 12-horsepower engine.\"\n",
    "inputs = tokenizer(question1, context, return_tensors='pt')\n",
    "\n",
    "for key, item in inputs.items():\n",
    "    print(key, ':', item)\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/minilm-uncased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(37) tensor(39)\n",
      "question='What mechanism did the W-Flyer use for control?'\n",
      "model_answer='ailerons'\n",
      "\n",
      "tensor(27) tensor(30)\n",
      "question='What Wright brothers used to fly?'\n",
      "model_answer='the w - flyer'\n",
      "\n",
      "tensor(17) tensor(20)\n",
      "question='When Wright brothers flew?'\n",
      "model_answer='december 17, 1903'\n",
      "\n",
      "tensor(42) tensor(42)\n",
      "question='How many horsepower had W-Flyer?'\n",
      "model_answer='12'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "for question in [question1, question2, question3, question4]:\n",
    "\n",
    "    inputs = tokenizer(question, context, return_tensors='pt')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    start = outputs.start_logits[0].argmax()\n",
    "    end = outputs.end_logits[0].argmax()\n",
    "    print(start, end)\n",
    "    model_answer = tokenizer.decode(inputs['input_ids'][0][start:end+1])\n",
    "    print(f'{question=}\\n{model_answer=}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Linux) Set Up ElasticSearch server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\n",
    "elasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n",
    "!wget -nc -q {url}\n",
    "!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "# Run Elasticsearch as a background process\n",
    "!chown -R daemon:daemon elasticsearch-7.9.2\n",
    "es_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'],\n",
    "                  stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
    "# Wait until Elasticsearch has started\n",
    "!sleep 30\n",
    "\n",
    "\n",
    "response = requests.get('http://localhost:9200')\n",
    "assert response.status_code == 200, \"Elasticsearch connection is not set ;(\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate document store and load SubjQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'haystack.document_store'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mhaystack\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_store\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39melasticsearch\u001b[39;00m \u001b[39mimport\u001b[39;00m ElasticsearchDocumentStore\n\u001b[0;32m      3\u001b[0m \u001b[39m# Return the document embedding for later use with dense retriever\u001b[39;00m\n\u001b[0;32m      4\u001b[0m document_store \u001b[39m=\u001b[39m ElasticsearchDocumentStore(return_embedding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'haystack.document_store'"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "# Return the document embedding for later use with dense retriever\n",
    "document_store = ElasticsearchDocumentStore(return_embedding=True)\n",
    "\n",
    "# Init empty list to keep documents for each split\n",
    "document_store_data = {\"train\": [], \"test\": [], \"validation\": []}\n",
    "\n",
    "# Load data to document_store\n",
    "for split, dataset in  subjqa.flatten().items():\n",
    "    # keep track of seen contexts to avoid duplicates\n",
    "    seen_contexts = set()\n",
    "    \n",
    "    for row in dataset:\n",
    "        context = row['context']\n",
    "\n",
    "        # skip duplicate reviews\n",
    "        if context in seen_contexts:\n",
    "            continue\n",
    "        seen_contexts.add(context)\n",
    "\n",
    "        # prepare the document\n",
    "        document = {\n",
    "            \"content\": context,\n",
    "            \"meta\": {\n",
    "                \"item_id\": row[\"title\"],\n",
    "                \"question_id\": row[\"id\"],\n",
    "                \"split\": split\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # append the document to the appropriate list\n",
    "        document_store_data[split].append(document)\n",
    "\n",
    "    # write all documents to the document_store for current split    \n",
    "    document_store.write_documents(document_store_data[split], index=\"document\")\n",
    "\n",
    "print(f\"Loaded {document_store.get_document_count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
