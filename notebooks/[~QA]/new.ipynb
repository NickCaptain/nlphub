{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset subjqa (C:/Users/nikit/.cache/huggingface/datasets/subjqa/electronics/1.1.0/2c12e496c4c675ab4a57ffb5d3f538f2e7b89793956e50da37126393ce23b6c6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a203b0c7e046998fcdfa7c91e91f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "subjqa = load_dataset('subjqa', name='electronics')\n",
    "\n",
    "MINI_CKPT = 'deepset/minilm-uncased-squad2'  # 0.1 GB\n",
    "ROBERTA_CKPT = 'deepset/roberta-base-squad2' # 0.5 GB\n",
    "\n",
    "model_ckpt = MINI_CKPT\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids : tensor([[  101,  2054,  7337,  2106,  1996,  1059,  1011, 23821,  2224,  2005,\n",
      "          2491,  1029,   102,  1996,  6119,  3428,  5520,  1996,  5013,  1011,\n",
      "          3498, 13297,  2006,  2285,  2459,  1010,  5778,  1012,  2037,  2948,\n",
      "          1010,  1996,  1059,  1011, 23821,  1010,  2109,  9932,  3917,  5644,\n",
      "          2005,  2491,  1998,  2018,  1037,  2260,  1011, 15149,  3194,  1012,\n",
      "           102]])\n",
      "token_type_ids : tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])\n",
      "attention_mask : tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]])\n",
      "[CLS] what mechanism did the w - flyer use for control? [SEP] the wright brothers flew the motor - operated airplane on december 17, 1903. their aircraft, the w - flyer, used ailerons for control and had a 12 - horsepower engine. [SEP]\n"
     ]
    }
   ],
   "source": [
    "question1 = \"What mechanism did the W-Flyer use for control?\" # ailerons\n",
    "question2 = \"What Wright brothers used to fly?\" # the W-Flyer\n",
    "question3 = \"When Wright brothers flew?\" # december 17, 1903\n",
    "question4 = \"How many horsepower had W-Flyer?\" # 12\n",
    "\n",
    "\n",
    "context = \"The Wright brothers flew the motor-operated airplane on December 17, 1903. Their aircraft, the W-Flyer, used ailerons for control and had a 12-horsepower engine.\"\n",
    "inputs = tokenizer(question1, context, return_tensors='pt')\n",
    "\n",
    "for key, item in inputs.items():\n",
    "    print(key, ':', item)\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=tensor(37) end=tensor(39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ailerons'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "start = outputs.start_logits[0].argmax()\n",
    "end = outputs.end_logits[0].argmax()\n",
    "print(f'{start=} {end=}')\n",
    "tokenizer.decode(inputs['input_ids'][0][start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
