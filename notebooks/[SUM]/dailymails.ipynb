{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this colab we:\n",
    "1. Import CNN dailymail (news, summarization) pairs.\n",
    "2. SUMMARIZE first example (about Hary Potter)\n",
    "    - baseline = first 3 senteces of article\n",
    "    - GPT-2 = append TL;DR and generate next tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets rouge_score sacrebleu evaluate py7zr pynvml xformers sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login() #             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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nikit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "WARNING:datasets.builder:Found cached dataset cnn_dailymail (C:/Users/nikit/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7ffc50ef6e4dafbe936afc49751d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")\n",
    "dataset['train'].column_names\n",
    "\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel ...\n",
      "- - - - -\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset['train'][0]\n",
    "print(sample['article'][29:211], '...')\n",
    "print('- - - - -')\n",
    "print(sample['highlights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Harry Potter star Daniel Radcliffe gets £20M fortune as he turns 18 Monday .\n",
      "Young actor says he has no plans to fritter his cash away .\n",
      "Radcliffe's earnings from first five Potter films have been held in trust fund . \n",
      "\n",
      "BASELINE\n",
      "LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \n",
      "\n",
      "GPT2\n",
      "Rudyard Kipling's youngest son is coming of age in \"Harry Potter and the Order of the Phoenix.\"Expect Radcliffe's first Potter film to break box office records in the UK, in spite of poor box office and ratings.If Radcliffe can't hit box office records, can the franchise live on in a different form?Thanks,  @SophieSchlutterer @TessBell @Gwen Blockchain.org  @jimmymonnett. \n",
      "\n",
      "T5\n",
      "the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties .he will be able to gamble in a casino, buy a drink or see the horror film \"Hostel: Part II\" his agent and publicist had no comment on his plans .his latest outing as the boy wizard is breaking records on both sides of the Atlantic . \n",
      "\n",
      "BART\n",
      "Harry Potter star Daniel Radcliffe turns 18 on Monday.He gains access to a reported £20 million ($41.1 million) fortune.Radcliffe's earnings from the first five Potter films have been held in a trust fund.Details of how he'll mark his landmark birthday are under wraps. \n",
      "\n",
      "PEGASUS\n",
      "Harry Potter star Daniel Radcliffe gains access to a reported £20 million fortune.\n",
      "Young actor says he has no plans to fritter his cash away.\n",
      "Radcliffe's earnings from the first five Potter films have been held in a trust fund . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline = first 3 senteces\n",
    "def three_sentence_summary(text):\n",
    "    return \" \".join(nltk.sent_tokenize(text)[:3])\n",
    "summaries['baseline'] = three_sentence_summary(sample['article'][:1000])\n",
    "\n",
    "# GPT-2 (not trained to SUMMARIZE but at least we can give a shot by appending \"TL;DR\")\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    gpt2_query = sample['article']  + \"\\nTL;DR:\\n\"\n",
    "    gpt2_pipe = transformers.pipeline(\"text-generation\", model=\"gpt2-xl\")\n",
    "    gpt2_out = gpt2_pipe(gpt2_query, max_length=1024, clean_up_tokenization_spaces=True)\n",
    "    summaries['gpt2'] = \"\".join(nltk.sent_tokenize(gpt2_out[0][\"generated_text\"][len(gpt2_query) :]))\n",
    "\n",
    "    # T5 fine-tuned on Summarization (CNN/DailyMail included)\n",
    "    t5_pipe = transformers.pipeline(\"summarization\", model=\"t5-large\")\n",
    "    t5_out = t5_pipe(sample['article'])\n",
    "    summaries['t5'] = \"\".join(nltk.sent_tokenize(t5_out[0][\"summary_text\"]))\n",
    "    clear_memory(t5_pipe)\n",
    "\n",
    "    # BART exclusively fine-tuned on CNN/DailyMail\n",
    "    bart_pipe = transformers.pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    bart_out = bart_pipe(sample['article'])\n",
    "    summaries['bart'] = \"\".join(nltk.sent_tokenize(bart_out[0][\"summary_text\"]))\n",
    "    clear_memory(bart_pipe)\n",
    "\n",
    "    # PEGASUS exclusively fine-tuned on CNN/DailyMail\n",
    "    pegasus_pipe = transformers.pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
    "    pegasus_out = pegasus_pipe(sample['article'])\n",
    "    summaries['pegasus'] = \"\".join(nltk.sent_tokenize(pegasus_out[0][\"summary_text\"])).replace(\" .<n>\", \".\\n\")\n",
    "    clear_memory(pegasus_pipe)\n",
    "    \n",
    "else: # import results\n",
    "    with open('summaries.json', 'r') as file:\n",
    "        summaries = json.load(file)\n",
    "    \n",
    "\n",
    "print(\"GROUND TRUTH\")\n",
    "print(sample['highlights'], '\\n')    \n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name], '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compute BLEU and also ROUGE\n",
    "\n",
    "First on Harry Potter sample, then on the whole CNN/DailyMail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Harry Potter\" scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>sacre_bleu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.309677</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.283871</td>\n",
       "      <td>0.283871</td>\n",
       "      <td>12.417712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.222497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.194175</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>13.933045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>26.486346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>47.368184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum  sacre_bleu\n",
       "baseline  0.309677  0.235294  0.283871   0.283871   12.417712\n",
       "gpt2      0.152381  0.019417  0.133333   0.133333    1.222497\n",
       "t5        0.266667  0.194175  0.228571   0.228571   13.933045\n",
       "bart      0.590909  0.348837  0.522727   0.522727   26.486346\n",
       "pegasus   0.800000  0.692308  0.800000   0.800000   47.368184"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate Bleu & Rouge on \"Harry Potter\"\n",
    "\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "records = []\n",
    "\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    \n",
    "    rouge_metric.add(prediction=[summaries[model_name]], reference=[sample['highlights']])\n",
    "    rouge_score = rouge_metric.compute()\n",
    "    # record_dict = dict((rn, rouge_score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    record_dict = rouge_score\n",
    "\n",
    "    bleu_metric.add(prediction=[summaries[model_name]], reference=[sample['highlights']])\n",
    "    bleu_score = bleu_metric.compute() \n",
    "    record_dict['sacre_bleu'] = bleu_score['score']\n",
    "\n",
    "    records.append(record_dict)\n",
    "\n",
    "print('\"Harry Potter\" scores:')\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.666425</td>\n",
       "      <td>0.295089</td>\n",
       "      <td>0.246468</td>\n",
       "      <td>0.246468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.666425  0.295089  0.246468   0.246468"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate BASELINE Rouge on 1k CNN/DailyMail\n",
    "test_sampled = dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                                column_text=\"article\",\n",
    "                                column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=[summaries],\n",
    "                     references=[dataset[column_summary]])\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    rouge_score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "    bleu_score = evaluate_summaries_baseline(test_sampled, bleu_metric)\n",
    "\n",
    "    # metrics = dict((rn, rouge_score[rn].mid.fmeasure) for rn in [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"])\n",
    "    metrics = rouge_score\n",
    "    metrics['sacre_bleu'] = bleu_score['score']\n",
    "else:\n",
    "    with open('metrics.json', 'r') as file:\n",
    "        metrics = json.load(file)\n",
    "\n",
    "# evaluated only on 10 examples\n",
    "#\t        rouge1\t    rouge2\t    rougeL\t    rougeLsum\n",
    "#  pegasus\t0.421244\t0.192581\t0.305494\t0.363489\n",
    "\n",
    "pd.DataFrame.from_dict(metrics, orient=\"index\", columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PEGASUS Rouge on CNN/DailyMail\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "test_sampled = dataset['test'].shuffle(seed=42).select(range(1000))\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                               batch_size=16, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
    "                        padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
    "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                clean_up_tokenization_spaces=True)\n",
    "               for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "    pegasus_tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    pegasus_model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "    score = evaluate_summaries_pegasus(test_sampled, rouge_metric, pegasus_model, pegasus_tokenizer, batch_size=8)\n",
    "else:\n",
    "    with open('pegasus_cnn_score.json', 'r') as file:\n",
    "        score = json.load(file)\n",
    "\n",
    "# published paper results: \n",
    "# R1 - 0.439, R2 - 0.212, RL - 0.407\n",
    "pd.DataFrame(score, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Pegasus on SAMSum\n",
    "Consider Summarization for another dataset : Dialogues (SAMSum).\n",
    "- The summarization should be more abstract and written from third-person-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset samsum (C:/Users/nikit/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39a82d6717d40c887734addd0827655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset('samsum')\n",
    "print(dataset_samsum)\n",
    "\n",
    "samsum_sample = dataset_samsum['test'][0]\n",
    "print('Dialogue:')\n",
    "print(samsum_sample['dialogue'])\n",
    "print('\\nSummary:')\n",
    "print(samsum_sample['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zero-shot PEGASUS on Hannah example\n",
    "\n",
    "pegasus_out = pegasus_pipe(dataset_samsum['test'][0]['dialogue'])\n",
    "print('Pegasus summary:')\n",
    "print(pegasus_out[0]['summary_text'].replace(' .<n>', '.\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the model tries to summarize by extracting the key sentences. \n",
    "- That is OK for CNN/DailyMail but not SAMSum\n",
    "\n",
    "Let's compute zero-shot **Rouge** of PEGASUS on whole SAMSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], rouge_metric, model,\n",
    "                                   tokenizer, column_text=\"dialogue\",\n",
    "                                   column_summary=\"summary\", batch_size=8)\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "\n",
    "# HG book: R1 - 0.296, R2 - 0.088, RL - 0.230, RLsum - 0.230\n",
    "pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_dataset_to_tensors(batch, tokenizer):\n",
    "\n",
    "    input_encodings = tokenizer(batch['dialogue'], max_length=1024, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(batch['summary'], max_length=128, truncation=True)\n",
    "    \n",
    "    return {'input_ids' : input_encodings['input_ids'],\n",
    "            'attention_mask' : input_encodings['attention_mask'],\n",
    "            'labels' : target_encodings['input_ids']}\n",
    "\n",
    "dataset_samsum_pt = dataset_samsum.map(cast_dataset_to_tensors, batched=True)\n",
    "\n",
    "columns = ['input_ids', 'labels', 'attention_mask']\n",
    "dataset_samsum_pt.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataccolator:\n",
    "- stack all tensors from batch\n",
    "- prepare decoder targets (teacher forcing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(pegasus_tokenizer, model=pegasus_model)\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "trainings_args = TrainingArguments(output_dir='pegasus-samsum', num_train_epochs=1,\n",
    "warmup_steps=500, per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "weight_decay=0.01, logging_steps=10, push_to_hub=True, evaluation_strategy='steps',\n",
    "eval_steps=500, save_steps=1e6, gradient_accumulation_steps=16)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "score = evaluate_summaries_pegasus(dataset['test'], rouge_metric, trainer.model, pegasus_tokenizer,\n",
    "batch_size=2, column_text='dialogue', column_summary='summary')\n",
    "\n",
    "rouge_ft_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_ft_dict, index=['pegasus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"Fine-tuning PEGASUS on SAMSum complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's generate Dialogue summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "\n",
    "\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "pipe = pipeline(\"summarization\", model=\"nikitakapitan/pegasus-samsum\")\n",
    "\n",
    "print('Dialogue:')\n",
    "print(samsum_sample['dialogue'])\n",
    "print('\\nReference Summary:')\n",
    "print(samsum_sample['summary'])\n",
    "print('\\nPegasus SAMSum summary:')\n",
    "print(pipe(sample_text, **gen_kwargs)[0]['summary_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
